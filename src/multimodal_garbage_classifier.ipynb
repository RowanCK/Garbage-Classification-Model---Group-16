{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RowanCK/Garbage-Classification-Model---Group-16/blob/main/multimodal_garbage_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEyHZc4KyTR8"
      },
      "source": [
        "# Garbage Classification Using Multimodal Deep Learning\n",
        "\n",
        "##### Team Members: Rowan (Yi-Kai) Chen, Das (Shih Ting) Tai, Ryan Lau, Zain Jelani\n",
        "#####Group Number: 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM2umeGQgU52"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "import glob\n",
        "from PIL import Image\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torchvision.models import resnet18\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "# from torchvision.models import ResNet50_Weights\n",
        "# from transformers import BertTokenizer, BertModel\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STKFvW08zMx5",
        "outputId": "154432d1-c77b-464c-de18-56a819d09e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pLNzjcNygoNP"
      },
      "outputs": [],
      "source": [
        "# Dataset directories\n",
        "# change these to your own directories where your data is located\n",
        "TRAINSET_DIR = '/content/drive/MyDrive/ENSF 617 - Introduction of Machine Learning /Assignment 2/garbage_sampled/garbage_sampled/CVPR_2024_dataset_Train'\n",
        "VALSET_DIR = '/content/drive/MyDrive/ENSF 617 - Introduction of Machine Learning /Assignment 2/garbage_sampled/garbage_sampled/CVPR_2024_dataset_Val'\n",
        "TESTSET_DIR = '/content/drive/MyDrive/ENSF 617 - Introduction of Machine Learning /Assignment 2/garbage_sampled/garbage_sampled/CVPR_2024_dataset_Test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx9MZqy2gq2y"
      },
      "source": [
        "# Class Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWFWyGOkyTSA"
      },
      "source": [
        "## Dataset class\n",
        "- Data Preprocessing\n",
        "  - Image Loading and Transformation:\n",
        "    - Resize images to 224x224 pixels to fit the model input\n",
        "    - Set Data Augmentation (Flips) to help the model generalize better\n",
        "    - Convert images to Tensors (Encoding images to numerical vectors)\n",
        "    - Normalize pixel values using ImageNet standards for stable training\n",
        "  - Text Preprocessing\n",
        "- Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset class\n",
        "# 'ImageFolder' - automatically maps subfolder names to class labels e.g., Green/xxx.png => Green; inherits from torch.utils.data.Dataset\n",
        "class MultiModalGarbageDataset(ImageFolder):\n",
        "  def __init__(self, root, tokenizer, max_len, transforms=None):\n",
        "        super().__init__(root, transform=transforms)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "        # 1. use ImageFolder to get img's path & label\n",
        "        path, label = self.samples[idx]\n",
        "\n",
        "        # 2. Image\n",
        "        image = self.loader(path)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # 3. Text\n",
        "        file_name = os.path.basename(path)\n",
        "        file_name_no_ext, _ = os.path.splitext(file_name)\n",
        "        # remove '_' and number\n",
        "        text = file_name_no_ext.replace('_', ' ')\n",
        "        text = re.sub(r'\\d+', '', text)\n",
        "        # Text Tokenization\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'image': image, # Image Tensor\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long),\n",
        "            'text': text,\n",
        "        }"
      ],
      "metadata": {
        "id": "XWktghJvLQT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXvs2V9_yTSA"
      },
      "source": [
        "## Model Class\n",
        "\n",
        "Our model integrates two branches:\n",
        "1. **Image Model**: Extracts features from garbage images using a pre-trained convolutional neural network (ResNet18).\n",
        "2. **Text Model**: Encodes textual descriptions using DistilBert embeddings.\n",
        "\n",
        "Both branches' outputs are combined in a fusion layer to produce the final classification prediction.\n",
        "\n",
        "### Components:\n",
        "- **Image Branch**: Extracts visual features from garbage images.\n",
        "- **Text Branch**: Encodes descriptions into meaningful embeddings.\n",
        "- **Fusion Layer**: Combines image and text features to generate a multimodal representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwQB296-g6ao"
      },
      "source": [
        "# Function Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traning Function"
      ],
      "metadata": {
        "id": "cwUTk1NIJvIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Function"
      ],
      "metadata": {
        "id": "Kjp_E-l4JxyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction Function"
      ],
      "metadata": {
        "id": "DssBkYdiJxjn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs_vWFoU3hS8"
      },
      "source": [
        "# Main Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvBtpHsRiCHe"
      },
      "source": [
        "## Pre-process data, define criterion, and initialize the multimodal model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deifne Image Transformations\n",
        "# Train/Val transformations (With Augmentation)\n",
        "torchvision_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),  # randomly flip images left/right\n",
        "    transforms.RandomVerticalFlip(),    # randomly flip images up/down\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Test Transformations (No Augmentation)\n",
        "torchvision_transform_test = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "PQhBg5BWQ-au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Load Dataset\n",
        "train_dataset = MultiModalGarbageDataset(TRAIN_PATH, tokenizer, max_len=24, transform=torchvision_transform)\n",
        "val_dataset   = MultiModalGarbageDataset(VAL_PATH,   tokenizer, max_len=24, transform=torchvision_transform)\n",
        "test_dataset  = MultiModalGarbageDataset(TEST_PATH,  tokenizer, max_len=24, transform=torchvision_transform_test)\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "qe4Sa5EcRJ48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_dataset.classes\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "SrIDyKTmRsos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer learning"
      ],
      "metadata": {
        "id": "5laxIdZfJmSm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1rUkMbB237k"
      },
      "source": [
        "## Set the main hyperparameters\n",
        "- batch size\n",
        "- learning rate\n",
        "- number of epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE = 2\n",
        "LEARNING_RATE = 0.0001"
      ],
      "metadata": {
        "id": "uOJnFo0EKm7j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUKz_UhNyTSD"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfsaLZmO362V"
      },
      "source": [
        "## Load best model for testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CePs4BVu4Bg2"
      },
      "source": [
        "## Test the model\n",
        "- Run prediction on your test set\n",
        "- Extract relevant metrics\n",
        "- Measure inference time"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}